\textbf{Knowledge bases (KB)} like DBpedia, YAGO and Wikidata store information about notable entities and the relations between those entities. For example, in Wikidata entities are considered notable, if
it either has a sitelink to a Wikimedia page, or is clearly identifiable and has relevant, public references,
or is required for structural purposes \cite{WikidataNotability}.
Approaches in populating the KBs with new information differs.
Wikidata employs mainly human collaboration for the creation and curation of new information \cite{Galarraga2016}.
YAGO in comparison extracts data from Wikipedia data boxes \cite{Galarraga2016}.
The issue of incompleteness arises in this context, as it is not realistic to assume that every bit of knowledge can or should be captured in the KBs.
\textbf{Ontologies} are necessary for modeling, sharing, and exchanging knowledge \cite{Hazman2011}, and are therefore integral in the functioning of a KB \cite{Wong2012}.
An ontology is a formal specification of knowledge consisting of concepts, relations and axioms for validation \cite{Maedche2001}. Therefore it describes a domain and how knowledge for the domain can be stored \cite{Wong2012}.
Each knowledge base explicitly or implicitly follows an ontology and can be considered an instantiation
of an ontology \cite{Wong2012}.
A main component of ontologies is the class hierarchy, also called taxonomy.
A taxonomy describes the subclass-superclass or child-parent relations between classes.
The superclass of a class is thereby a more general concept.
Obtaining an ontology with a detailed as possible taxonomy is desirable,
since it allows more detailed representation of knowledge, as well as better reasoning about this knowledge
\cite{Wong2012}.
Types of ontologies range from lightweight ontologies like glossaries and taxonomies 
to heavyweight ontologies like data models and description logics
\cite{Wong2012}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/introduction/example_taxonomy.pdf}
\caption{Classification of orphan class in Wikidata's taxonomy}
\label{fig:problem example}
\end{figure}

The goal of this thesis is the development and evaluation of approaches to increase the completeness of ontological taxonomies.
Specifically, the problem of classifying \textbf{orphan classes} is solved.
Orphan classes are classes in a taxonomy, which have no superclasses (parents) and are not the root of the taxonomy.
A class without superclasses is interpreted as a most general concept in a taxonomy,
since it has to be assumed that no further generalizations are possible.
Because this is not the case for orphan classes, which are less general than the root class, e.g.\entity{} in Wikidata,
orphan classes should not exist in a taxonomy.
An example, for such a classification problem is given in Figure~\ref{fig:problem example}.
An extract of the Wikidata taxonomy is shown. 
The class \textit{reversal film} is an orphan class in the taxonomy, since it is has no superclass.
A possible solution is represented by the dotted arrow, which places \textit{photographic film} as superclass of \textit{reversal film}.
It has to be noted that additionally all superclasses of \textit{photographic film} are also valid solutions to the problem for the orphan class \textit{reversal film},
since the subclass-of relationship is transitive.
A solution to the problem should find the most specific superclass for a given orphan class \cite{Doan2002}.
I develop an algorithm with the task of classifying such orphan classes into a given taxonomy.
The algorithm uses neural word embeddings, as developed by \fullcite{Mikolov2013}. This is motivated by the effectiveness of neural networks in other context-sensitive tasks
like language processing \cite{Mikolov2013} \cite{Kalchbrenner2014} \cite{Arisoy2012}, image generation \cite{Gregor2015} etc.
Neural word embeddings are interesting, because they are able to represent the semantics and lexicographic properties of words \cite{Mikolov2013} and graphs \cite{Cao2016} as
low-dimensional vectors. Thereby application of existing general-purpose methods such as classifiers, like kNN or SVM, regression models, or neural networks
are enabled for complex, contextual entities.
Representation of ontological classes with word embeddings is discussed in the thesis to enable the classification of orphan classes. 
Existing applications of neural word embeddings have shown great effect in the construction of taxonomies \cite{Fu2014},
graph representation \cite{Cao2016} and semantic similarity tasks \cite{Mikolov2013a} \cite{Levy2014}.
Different approaches in using neural word embeddings for classification of orphan classes are considered and evaluated in this work.

In this work, the taxonomy of Wikidata is considered as case example, as it provides a high number of entities ($24,507,102$ in \dumpdate{} \cite{WikidataDump}),
and a big taxonomy consisting of $1,299,501$ classes \cite{WikidataDump}.
At this time, Wikidata's taxonomy is mostly maintained by human editors.
The solution developed by the thesis should be able to support the editors in improving the completeness of the taxonomy by reducing the number of orphan classes
and refining the existing taxonomic relations between classes.
The refinement process, supported by the algorithm, would be semi-manual. Editors
would have to confirm or correct the output of the algorithm to ensure that no wrong
information is added to Wikidata.

The thesis is structured as follows.
In Chapter~\ref{section:foundations} the problem will be formally defined (\ref{section:wikidata}, \ref{section:taxonomy}, \ref{section:similarity}, \ref{section:problem statement})
and related work in the fields of neural networks (\ref{section:neural networks}) and ontology learning (\ref{section:ontology learning}) discussed for the use in this work.
Section~\ref{section:neural networks} introduces the notion of neural networks and discusses work dealing with neural word and graph embeddings.
Section~\ref{section:ontology learning} compares the problem, solved by the thesis, to related work in the field of ontology learning. 
Subsequently, the problem is classified, solutions to similar problems analyzed and the novelty of the work justified.
Chapter~\ref{section:taxonomy analysis} describes the Wikidata data set used as case example for the implementation and evaluation of the proposed hybrid algorithm. 
Chapter~\ref{section:algorithm} describes the components of the developed baseline algorithm and variations, which potentially improve the effectiveness of the method.
Chapter~\ref{section:evaluation} describes the evaluation methodology and presents the results.
The baseline algorithm and proposed improvements are evaluated.

Formatting of text obeys the following rules to distinguish between defined concepts, Wikidata entities,
and different types of citations.
Italic text indicates Wikidata entities like \entity{} or \textit{instance of (P31)}.
Bold text indicates the first occurrence of a relevant concept, such as \textbf{orphan class}.
Such concepts are described in the following sentences and, if necessary, formally defined.
In-line quotes are indicated by quotation marks. The corresponding citation is placed after the quote.
Multi-line quotes are indented and framed with a solid line. 
The quote is introduced by a short sentence, which contains the reference.

