\textbf{TODO: Motivation.  Related work. Justify novelty. Solution. Evaluation.}

The thesis is structured as follows.
\textbf{TODO: apply changes of outline to this paragraph}
Section~\ref{section:foundations} defines the concepts related to Wikidata, taxonomies, similarity measures
and k-nearest-neighbors classification. Subsequently, the problem statement is formalized and its corresponding
challenges listed.
Section~\ref{section:neural networks} explains the notion of neural networks at
the example of a simple feedforward network with backpropagation.
Subsequently, neural networks for graph and word representation are compared
in regards to suitability in the problem's context.
Section~\ref{section:ontology learning} compares the problem, solved by the thesis, to related work
in the field of ontology learning. The problem is classified and solutions to similar problems analyzed.
The novelty of the work is justified.
Section~\ref{section:taxonomy analysis} presents the results of the analysis of Wikidata's taxonomy.
Characteristics of unlinked classes are identified, and a specific subset of unlinked classes chosen,
which fulfills necessary requirements as input for an algorithm.
Section~\ref{section:algorithm} describes the developed baseline algorithm, which combines
Word2Vec by \fullcite{Mikolov2013} and k-nearest-neighbors.
Possible variations of the algorithm are presented and compared in regards to possible gains and problems. 
One of these variations is also implemented for evaluation purposes.
Section~\ref{section:evaluation} describes the evaluation methodology and presents the results.
The baseline algorithm, using multiple different sets of different hyperparameters,  and a variation of it will be compared.
Section~\ref{section:conclusion} summarizes the results of the thesis and lists possible future work,
which could extend upon it.

